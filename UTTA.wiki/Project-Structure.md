# Project Structure

This page explains the UTTA project structure, organization, and design philosophy. It also identifies potential redundancies and optimization opportunities.

## ğŸ“‚ Root Directory

The UTTA repository is organized into these main components:

```
UTTA/
â”œâ”€â”€ llm-chatbot-framework/   # Core chatbot functionality
â”œâ”€â”€ llm-fine-tuning/         # Model fine-tuning capabilities
â”œâ”€â”€ benchmark_results/       # Results from benchmark tests
â”œâ”€â”€ evaluation_results/      # Results from evaluation runs
â”œâ”€â”€ offload/                 # Temporary model offloading
â”œâ”€â”€ wiki_backup/             # Wiki backup files
â”œâ”€â”€ UTTA.wiki/               # Wiki documentation
â”œâ”€â”€ .git/                    # Git repository data
â”œâ”€â”€ README.md                # Project overview
â””â”€â”€ LICENSE                  # MIT License
```

## ğŸ¤– LLM Chatbot Framework

The chatbot framework (`llm-chatbot-framework/`) is the core implementation for the teaching assistant functionality:

```
llm-chatbot-framework/
â”œâ”€â”€ src/                     # Source code
â”‚   â”œâ”€â”€ core/                # Core functionality
â”‚   â”œâ”€â”€ llm/                 # LLM integrations
â”‚   â”œâ”€â”€ retrieval/           # Knowledge retrieval
â”‚   â”œâ”€â”€ web/                 # Web interface
â”‚   â”œâ”€â”€ utils/               # Utility functions
â”‚   â””â”€â”€ evaluation/          # Evaluation tools
â”œâ”€â”€ tests/                   # Test suite
â”œâ”€â”€ examples/                # Example implementations
â”œâ”€â”€ knowledge_base/          # Educational content
â”œâ”€â”€ docs/                    # Documentation
â”œâ”€â”€ config/                  # Configuration files
â”œâ”€â”€ data/                    # Data resources
â”œâ”€â”€ cache/                   # Cache storage
â”œâ”€â”€ tools/                   # Development tools
â””â”€â”€ config.py                # Main configuration
```

## ğŸ”„ LLM Fine-Tuning Module

The fine-tuning module (`llm-fine-tuning/`) provides tools for customizing LLMs for educational tasks:

```
llm-fine-tuning/
â”œâ”€â”€ src/                     # Source code
â”‚   â”œâ”€â”€ dspy/                # DSPy fine-tuning
â”‚   â”œâ”€â”€ huggingface/         # HuggingFace fine-tuning
â”‚   â”œâ”€â”€ openai/              # OpenAI fine-tuning
â”‚   â””â”€â”€ utils/               # Utility functions
â”œâ”€â”€ examples/                # Example fine-tuning
â”œâ”€â”€ finetune.py              # Main entry point
â”œâ”€â”€ compare_approaches.py    # Compare fine-tuning methods
â”œâ”€â”€ check_structure.py       # Validate dataset structure
â””â”€â”€ setup.py                 # Package setup
```

## ğŸ“Š Results Directories

The project includes directories for storing benchmark and evaluation results:

```
benchmark_results/           # Benchmark performance data
evaluation_results/          # Evaluation metrics and analyses
```

## ğŸ” Identified Redundancies

During our review, we identified several potential redundancies in the codebase:

1. **Duplicate Benchmark Directories**:
   - `benchmark_results/` in the root
   - `llm-chatbot-framework/benchmark_results/`
   
   **Recommendation**: Consolidate into a single `benchmark_results/` directory at the root level.

2. **Duplicate Evaluation Directories**:
   - `evaluation_results/` in the root
   - `llm-chatbot-framework/evaluation_results/`
   
   **Recommendation**: Consolidate into a single `evaluation_results/` directory at the root level.

3. **Nested Fine-Tuning Directory**:
   - `llm-fine-tuning/` in the root
   - `llm-chatbot-framework/llm-fine-tuning/`
   
   **Recommendation**: Remove the nested directory and reference the root-level `llm-fine-tuning/` module instead.

4. **File Placement Issues**:
   - `fine_tuning_lesson.html` at the root level
   - `=0.21.0` file at the root level (possibly a fragment from a dependency installation)
   
   **Recommendation**: Move `fine_tuning_lesson.html` to the `llm-fine-tuning/docs/` directory and remove the `=0.21.0` file.

## ğŸ”„ Dependency Management

The project uses multiple requirements files:

- `llm-chatbot-framework/requirements.txt`
- `llm-fine-tuning/requirements.txt`

**Recommendation**: Consider creating a unified requirements management approach with:
- A base `requirements.txt` at the root level
- Component-specific requirements files that use `-r ../requirements.txt` to include the base requirements

## ğŸŒ Project Interaction Flow

The following diagram illustrates how the different components interact:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        llm-fine-tuning          â”‚
â”‚                                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ DSPy    â”‚ â”‚ OpenAI â”‚ â”‚ HF   â”‚ â”‚
â”‚ â”‚ Tuning  â”‚ â”‚ Tuning â”‚ â”‚ Tune â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”˜ â”‚
â”‚      â”‚           â”‚          â”‚    â”‚
â””â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”˜
       â”‚           â”‚          â”‚
       â–¼           â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      llm-chatbot-framework      â”‚
â”‚                                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Core    â”‚ â”‚ Web UI â”‚ â”‚ Eval â”‚ â”‚
â”‚ â”‚ Engine  â”‚â—„â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”˜ â”‚
â”‚ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â”‚              â”‚    â”‚
â”‚      â”‚      â”‚              â”‚    â”‚
â””â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”˜
       â”‚      â”‚              â”‚
       â–¼      â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Student â”‚ â”‚ Web â”‚  â”‚Performanceâ”‚
â”‚ Queries â”‚ â”‚Usersâ”‚  â”‚ Metrics   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Development Workflow

The recommended development workflow is:

1. Set up the environment following the [Environment Setup](Environment-Setup) guide
2. Explore example implementations in both main components
3. Implement your educational use case:
   - Prepare datasets using guidance from [Dataset Preparation](Dataset-Preparation)
   - Fine-tune models using the appropriate approach (DSPy, OpenAI, HuggingFace)
   - Integrate the fine-tuned model with the chatbot framework
   - Evaluate performance using the evaluation tools
   - Iterate and improve based on evaluation results

## ğŸ”— Directory References

- [llm-chatbot-framework/src/](https://github.com/UVU-AI-Innovate/UTTA/tree/main/llm-chatbot-framework/src) - Core implementation
- [llm-fine-tuning/src/](https://github.com/UVU-AI-Innovate/UTTA/tree/main/llm-fine-tuning/src) - Fine-tuning implementation
- [examples/](https://github.com/UVU-AI-Innovate/UTTA/tree/main/llm-chatbot-framework/examples) - Usage examples 